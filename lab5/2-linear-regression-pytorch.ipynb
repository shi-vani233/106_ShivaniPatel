{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1604,
     "status": "ok",
     "timestamp": 1596557525423,
     "user": {
      "displayName": "Prof. Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggt3sg6X_951s0boD3SSJvqRng4AQaC3MhTBtGQ9Q=s64",
      "userId": "16159546014304882594"
     },
     "user_tz": -330
    },
    "id": "v0BtAX1--7l_"
   },
   "outputs": [],
   "source": [
    "# Import Numpy & PyTorch\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ecc6e79cdfb6a8ca882895ccc895b61b960b0a04",
    "colab_type": "text",
    "id": "i1HSrBDb-7t9"
   },
   "source": [
    "## Linear Regression Model using PyTorch built-ins\n",
    "\n",
    "Let's re-implement the same model using some built-in functions and classes from PyTorch.\n",
    "\n",
    "And now using two different targets: Apples and Oranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "ce66cf0d09a3f38bf2f00ea40418c56d98f1f814",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2201,
     "status": "ok",
     "timestamp": 1596557526042,
     "user": {
      "displayName": "Prof. Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggt3sg6X_951s0boD3SSJvqRng4AQaC3MhTBtGQ9Q=s64",
      "userId": "16159546014304882594"
     },
     "user_tz": -330
    },
    "id": "iXiEK54j-7t-"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "74bb18bd01ac809079eeb8d05695206e8ba02069",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2186,
     "status": "ok",
     "timestamp": 1596557526045,
     "user": {
      "displayName": "Prof. Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggt3sg6X_951s0boD3SSJvqRng4AQaC3MhTBtGQ9Q=s64",
      "userId": "16159546014304882594"
     },
     "user_tz": -330
    },
    "id": "wCsxgTWO-7uM"
   },
   "outputs": [],
   "source": [
    "# Input (temp, rainfall, humidity)\n",
    "inputs = np.array([[73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69, 96, 70], [73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69, 96, 70], [73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69, 96, 70]], dtype='float32')\n",
    "# Targets (apples, oranges)\n",
    "targets = np.array([[56, 70], [81, 101], [119, 133], [22, 37], [103, 119], \n",
    "                    [56, 70], [81, 101], [119, 133], [22, 37], [103, 119], \n",
    "                    [56, 70], [81, 101], [119, 133], [22, 37], [103, 119]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "d94b355f55250e9c7dcff668920f02d7c5c04925",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2169,
     "status": "ok",
     "timestamp": 1596557526049,
     "user": {
      "displayName": "Prof. Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggt3sg6X_951s0boD3SSJvqRng4AQaC3MhTBtGQ9Q=s64",
      "userId": "16159546014304882594"
     },
     "user_tz": -330
    },
    "id": "nJRlm4-N-7uY"
   },
   "outputs": [],
   "source": [
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a0665466eb5401f40a816b323a34450b2c052c41",
    "colab_type": "text",
    "id": "O6JT5Ng6-7uj"
   },
   "source": [
    "### Dataset and DataLoader\n",
    "\n",
    "We'll create a `TensorDataset`, which allows access to rows from `inputs` and `targets` as tuples. We'll also create a DataLoader, to split the data into batches while training. It also provides other utilities like shuffling and sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "206f5fd0473386476b23477bf38d2c327b6376c9",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2156,
     "status": "ok",
     "timestamp": 1596557526052,
     "user": {
      "displayName": "Prof. Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggt3sg6X_951s0boD3SSJvqRng4AQaC3MhTBtGQ9Q=s64",
      "userId": "16159546014304882594"
     },
     "user_tz": -330
    },
    "id": "iGYdbuWc-7ul"
   },
   "outputs": [],
   "source": [
    "# Import tensor dataset & data loader\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "c47a4f2f86fda3918094e01cf7ab0698bbb5acc7",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2147,
     "status": "ok",
     "timestamp": 1596557526056,
     "user": {
      "displayName": "Prof. Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggt3sg6X_951s0boD3SSJvqRng4AQaC3MhTBtGQ9Q=s64",
      "userId": "16159546014304882594"
     },
     "user_tz": -330
    },
    "id": "LY_cq6Bf-7ux"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 73.,  67.,  43.],\n",
       "         [ 91.,  88.,  64.],\n",
       "         [ 87., 134.,  58.]]),\n",
       " tensor([[ 56.,  70.],\n",
       "         [ 81., 101.],\n",
       "         [119., 133.]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define dataset\n",
    "dataset = TensorDataset(inputs, targets)\n",
    "dataset[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "0a2f69126319d738b82ae67d5d404ecd6161bfac",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2139,
     "status": "ok",
     "timestamp": 1596557526059,
     "user": {
      "displayName": "Prof. Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggt3sg6X_951s0boD3SSJvqRng4AQaC3MhTBtGQ9Q=s64",
      "userId": "16159546014304882594"
     },
     "user_tz": -330
    },
    "id": "I-_dMpco-7u-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 87., 134.,  58.],\n",
       "         [102.,  43.,  37.],\n",
       "         [ 73.,  67.,  43.],\n",
       "         [ 87., 134.,  58.],\n",
       "         [102.,  43.,  37.]]),\n",
       " tensor([[119., 133.],\n",
       "         [ 22.,  37.],\n",
       "         [ 56.,  70.],\n",
       "         [119., 133.],\n",
       "         [ 22.,  37.]])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define data loader\n",
    "batch_size = 5\n",
    "DL = DataLoader(dataset, batch_size, shuffle=True)\n",
    "next(iter(DL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "276a262e1b9e3a048bcd32989013f9c501c59037",
    "colab_type": "text",
    "id": "Dq8gUbVx-7vK"
   },
   "source": [
    "### nn.Linear\n",
    "Instead of initializing the weights & biases manually, we can define the model using `nn.Linear`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "59da3506559a0640d80d18f77b02726a1757be2f",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2128,
     "status": "ok",
     "timestamp": 1596557526062,
     "user": {
      "displayName": "Prof. Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggt3sg6X_951s0boD3SSJvqRng4AQaC3MhTBtGQ9Q=s64",
      "userId": "16159546014304882594"
     },
     "user_tz": -330
    },
    "id": "sKa873ZD-7vN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.3879, -0.4304,  0.3922],\n",
      "        [-0.2189, -0.2490, -0.5698]], requires_grad=True)\n",
      "---------\n",
      "Parameter containing:\n",
      "tensor([-0.0044,  0.5062], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "final_model = nn.Linear(3, 2)\n",
    "print(final_model.weight, end=\"\\n---------\\n\")\n",
    "print(final_model.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b3a4a8c499a4680f2533329712de034671dd1cdd",
    "colab_type": "text",
    "id": "rku14lz3-7vX"
   },
   "source": [
    "### Optimizer\n",
    "Instead of manually manipulating the weights & biases using gradients, we can use the optimizer `optim.SGD`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "1848398bd1ced8c25a7bb55612cf32a774500280",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2117,
     "status": "ok",
     "timestamp": 1596557526064,
     "user": {
      "displayName": "Prof. Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggt3sg6X_951s0boD3SSJvqRng4AQaC3MhTBtGQ9Q=s64",
      "userId": "16159546014304882594"
     },
     "user_tz": -330
    },
    "id": "Yd4H-T8g-7va"
   },
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "opt = torch.optim.SGD(final_model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "28cbe62be55010bd11b31d819cff38da5a772b18",
    "colab_type": "text",
    "id": "V2ktEA-C-7vl"
   },
   "source": [
    "### Loss Function\n",
    "Instead of defining a loss function manually, we can use the built-in loss function `mse_loss`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "69d7f4e8e27ccd077f711da27f8bede8aa711893",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2110,
     "status": "ok",
     "timestamp": 1596557526068,
     "user": {
      "displayName": "Prof. Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggt3sg6X_951s0boD3SSJvqRng4AQaC3MhTBtGQ9Q=s64",
      "userId": "16159546014304882594"
     },
     "user_tz": -330
    },
    "id": "TF2xmzgO-7vo"
   },
   "outputs": [],
   "source": [
    "# Import nn.functional\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "a02ff888ed4be720fd9ca376022d8fdcf2559683",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2099,
     "status": "ok",
     "timestamp": 1596557526070,
     "user": {
      "displayName": "Prof. Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggt3sg6X_951s0boD3SSJvqRng4AQaC3MhTBtGQ9Q=s64",
      "userId": "16159546014304882594"
     },
     "user_tz": -330
    },
    "id": "hSgxvr8N-7vz"
   },
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "loss_fn = F.mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "a540adf76725ea9968025f6c029fdd251bdada6c",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2087,
     "status": "ok",
     "timestamp": 1596557526072,
     "user": {
      "displayName": "Prof. Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggt3sg6X_951s0boD3SSJvqRng4AQaC3MhTBtGQ9Q=s64",
      "userId": "16159546014304882594"
     },
     "user_tz": -330
    },
    "id": "9vyVL5io-7wA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(22877.4316, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss = loss_fn(final_model(inputs) , targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e833614a69ff18c554a3d89f643ae2f11e0260f6",
    "colab_type": "text",
    "id": "9jbPdkiO-7wM"
   },
   "source": [
    "### Train the model\n",
    "\n",
    "We are ready to train the model now. We can define a utility function `fit` which trains the model for a given number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "128bc7260221f5338edf8b503c75f0c7d1cce7e8",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2081,
     "status": "ok",
     "timestamp": 1596557526075,
     "user": {
      "displayName": "Prof. Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggt3sg6X_951s0boD3SSJvqRng4AQaC3MhTBtGQ9Q=s64",
      "userId": "16159546014304882594"
     },
     "user_tz": -330
    },
    "id": "zDnWui7g-7wP"
   },
   "outputs": [],
   "source": [
    "# Define a utility function to train the model\n",
    "def fit(num_epochs, final_model, loss_fn, opt):\n",
    "    for epoch in range(num_epochs):\n",
    "        for xb,yb in DL:\n",
    "            # Generate predictions\n",
    "            pred = final_model(xb)\n",
    "            loss = loss_fn(pred,yb)\n",
    "            # Perform gradient descent\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "    print('Training loss: ', loss_fn(final_model(inputs), targets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "ae8ca4686cf6a68f6c9ca93bf3d227abe96c2201",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2073,
     "status": "ok",
     "timestamp": 1596557526078,
     "user": {
      "displayName": "Prof. Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggt3sg6X_951s0boD3SSJvqRng4AQaC3MhTBtGQ9Q=s64",
      "userId": "16159546014304882594"
     },
     "user_tz": -330
    },
    "id": "Gd8tiT_q-7wa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:  tensor(37.1367, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model for 100 epochs\n",
    "fit(100 , final_model , loss_fn, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "32588a47d0478772a1f08fa55874a322630bd0b6",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2065,
     "status": "ok",
     "timestamp": 1596557526080,
     "user": {
      "displayName": "Prof. Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggt3sg6X_951s0boD3SSJvqRng4AQaC3MhTBtGQ9Q=s64",
      "userId": "16159546014304882594"
     },
     "user_tz": -330
    },
    "id": "c3Bf-Emn-7wj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 58.0482,  71.7960],\n",
       "        [ 83.9512,  96.0745],\n",
       "        [113.3484, 139.8448],\n",
       "        [ 26.2983,  45.5296],\n",
       "        [101.9072, 106.3604],\n",
       "        [ 58.0482,  71.7960],\n",
       "        [ 83.9512,  96.0745],\n",
       "        [113.3484, 139.8448],\n",
       "        [ 26.2983,  45.5296],\n",
       "        [101.9072, 106.3604],\n",
       "        [ 58.0482,  71.7960],\n",
       "        [ 83.9512,  96.0745],\n",
       "        [113.3484, 139.8448],\n",
       "        [ 26.2983,  45.5296],\n",
       "        [101.9072, 106.3604]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Generate predictions\n",
    "preds = final_model(inputs)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "12d757c0f37c2e3af65cf9d4b59878cc10c65acf",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2659,
     "status": "ok",
     "timestamp": 1596557526686,
     "user": {
      "displayName": "Prof. Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggt3sg6X_951s0boD3SSJvqRng4AQaC3MhTBtGQ9Q=s64",
      "userId": "16159546014304882594"
     },
     "user_tz": -330
    },
    "id": "_gDGmiHl-7wr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.],\n",
       "        [ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.],\n",
       "        [ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare with targets\n",
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2448d9832722f4f2813f8bd80b91daefd901dc2e",
    "colab_type": "text",
    "id": "b9nvUidI-7xD"
   },
   "source": [
    "Now we can define the model, optimizer and loss function exactly as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "e94de6868c76803a998c1c1934ed229c826f3b8c",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2651,
     "status": "ok",
     "timestamp": 1596557526688,
     "user": {
      "displayName": "Prof. Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggt3sg6X_951s0boD3SSJvqRng4AQaC3MhTBtGQ9Q=s64",
      "userId": "16159546014304882594"
     },
     "user_tz": -330
    },
    "id": "d3esiKz3-7xT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:  tensor(15.8004, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "fit(100 , final_model , loss_fn, opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eAyCq48TMlWJ"
   },
   "source": [
    "## Exercise 1:\n",
    " Try Linear Regression just using numpy (Without Tensorflow/Pytorch or other torch library). You can optionally use sklearn (if you want)\n",
    " \n",
    " \n",
    "## Exercise 2:\n",
    " Try Linear regression on same prediction data using Tensorflow\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input (temp, rainfall, humidity)\n",
    "inputs = np.array([[73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69, 96, 70], [73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69, 96, 70], [73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69, 96, 70]], dtype='float32')\n",
    "# Targets (apples, oranges)\n",
    "targets = np.array([[56, 70], [81, 101], [119, 133], [22, 37], [103, 119], \n",
    "                    [56, 70], [81, 101], [119, 133], [22, 37], [103, 119], \n",
    "                    [56, 70], [81, 101], [119, 133], [22, 37], [103, 119]], dtype='float32')\n",
    "\n",
    "x_shape = inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:\n",
      "[[0.73266609 0.81397813 0.30146181]\n",
      " [0.57308328 0.02550587 0.82354316]]\n",
      "Biases:\n",
      "[[0.54271117 0.94240298]\n",
      " [0.60453688 0.9571017 ]\n",
      " [0.48019233 0.25695075]\n",
      " [0.11295721 0.00529217]\n",
      " [0.76333078 0.56001356]\n",
      " [0.01472286 0.99117333]\n",
      " [0.28973774 0.06966777]\n",
      " [0.49865902 0.91012109]\n",
      " [0.64505541 0.21941785]\n",
      " [0.29706507 0.53375311]\n",
      " [0.39398807 0.48498531]\n",
      " [0.24366418 0.38278502]\n",
      " [0.23025406 0.47921564]\n",
      " [0.36161226 0.58221162]\n",
      " [0.67273645 0.21190365]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# weights and biases\n",
    "weights = np.random.rand(2,3)\n",
    "biases = np.random.rand(15,2)\n",
    "print(\"Weights:\",weights,sep='\\n')\n",
    "print(\"Biases:\",biases,sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "def model(x):\n",
    "    return x @ np.transpose(weights) + biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate predictions\n",
    "preds = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions : \n",
      "[[121.52672809  79.89873171]\n",
      " [158.20078209 108.05895919]\n",
      " [190.77999623 101.29848632]\n",
      " [121.00004485  90.02763599]\n",
      " [150.56151787 100.19934493]\n",
      " [120.99873978  79.94750206]\n",
      " [157.88598295 107.17152526]\n",
      " [190.79846291 101.95165665]\n",
      " [121.53214304  90.24176168]\n",
      " [150.09525215 100.17308448]\n",
      " [121.37800499  79.44131405]\n",
      " [157.83990939 107.48464251]\n",
      " [190.53005795 101.52075121]\n",
      " [121.24869989  90.60455545]\n",
      " [150.47092353  99.85123501]]\n",
      "Targets : \n",
      "[[ 56.  70.]\n",
      " [ 81. 101.]\n",
      " [119. 133.]\n",
      " [ 22.  37.]\n",
      " [103. 119.]\n",
      " [ 56.  70.]\n",
      " [ 81. 101.]\n",
      " [119. 133.]\n",
      " [ 22.  37.]\n",
      " [103. 119.]\n",
      " [ 56.  70.]\n",
      " [ 81. 101.]\n",
      " [119. 133.]\n",
      " [ 22.  37.]\n",
      " [103. 119.]]\n"
     ]
    }
   ],
   "source": [
    "# Compare with targets\n",
    "print(\"Predictions : \", preds, sep=\"\\n\")\n",
    "print(\"Targets : \",targets, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE loss\n",
    "def mse(t1, t2):\n",
    "    diff = t1 - t2\n",
    "    return np.sum(diff * diff) / len(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6350.315560321062\n"
     ]
    }
   ],
   "source": [
    "# Compute loss\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights_grad:\n",
      "[[12561.35777172 11829.39441035  7552.83758461]\n",
      " [ 1083.16152017 -1000.72687131  -133.75502411]]\n",
      "biases_grad:\n",
      "[[ 8.73689708  1.31983089]\n",
      " [10.29343761  0.94119456]\n",
      " [ 9.57066616 -4.22686849]\n",
      " [13.20000598  7.07035147]\n",
      " [ 6.34153572 -2.50675401]\n",
      " [ 8.66649864  1.32633361]\n",
      " [10.25146439  0.82287003]\n",
      " [ 9.57312839 -4.13977911]\n",
      " [13.27095241  7.09890156]\n",
      " [ 6.27936695 -2.5102554 ]\n",
      " [ 8.71706733  1.25884187]\n",
      " [10.24532125  0.864619  ]\n",
      " [ 9.53734106 -4.19723317]\n",
      " [13.23315999  7.14727406]\n",
      " [ 6.32945647 -2.55316866]]\n"
     ]
    }
   ],
   "source": [
    "# compute gradients\n",
    "biases_grad = (preds-targets)*2/x_shape[0]\n",
    "weights_grad = (np.matmul(np.transpose((preds-targets)),inputs))*2/x_shape[0]\n",
    "\n",
    "print(\"weights_grad:\",weights_grad, sep=\"\\n\")\n",
    "print(\"biases_grad:\",biases_grad, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust weights\n",
    "weights -= weights_grad * 1e-5\n",
    "biases -= biases_grad * 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:\n",
      "[[0.60705251 0.69568418 0.22593343]\n",
      " [0.56225166 0.03551314 0.82488071]]\n",
      "Biases:\n",
      "[[0.5426238  0.94238978]\n",
      " [0.60443394 0.95709229]\n",
      " [0.48009663 0.25699302]\n",
      " [0.11282521 0.00522146]\n",
      " [0.76326736 0.56003863]\n",
      " [0.01463619 0.99116007]\n",
      " [0.28963522 0.06965954]\n",
      " [0.49856329 0.91016249]\n",
      " [0.6449227  0.21934687]\n",
      " [0.29700227 0.53377821]\n",
      " [0.3939009  0.48497273]\n",
      " [0.24356173 0.38277638]\n",
      " [0.23015868 0.47925762]\n",
      " [0.36147993 0.58214015]\n",
      " [0.67267315 0.21192918]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Weights:\",weights,sep='\\n')\n",
    "print(\"Biases:\",biases,sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3413.8850290907567\n"
     ]
    }
   ],
   "source": [
    "# Calculate loss\n",
    "preds = model(inputs)\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeating same for 200 times\n",
    "for i in range(200):\n",
    "    preds = model(inputs)\n",
    "    loss = mse(preds, targets)\n",
    "    \n",
    "    biases_grad = ((((inputs@np.transpose(weights))+biases)-targets))*2/x_shape[0]\n",
    "    weights_grad = (np.matmul(np.transpose((((inputs@np.transpose(weights))+biases)-targets)),inputs))*2/x_shape[0]\n",
    "\n",
    "    weights -= weights_grad * 1e-5\n",
    "    biases -= biases_grad * 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.042988070753566\n"
     ]
    }
   ],
   "source": [
    "# Calculate loss\n",
    "preds = model(inputs)\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 58.25171712  71.55681747]\n",
      " [ 80.04430224 101.67736266]\n",
      " [122.56621035 130.14649672]\n",
      " [ 25.64971098  40.73691631]\n",
      " [ 95.41745479 117.7947015 ]\n",
      " [ 57.72387029  71.60557476]\n",
      " [ 79.72958746 100.79016652]\n",
      " [122.58467209 130.79949203]\n",
      " [ 26.18166659  40.95098462]\n",
      " [ 94.95131401 117.76844809]\n",
      " [ 58.10303387  71.09952238]\n",
      " [ 79.68352624 101.10319987]\n",
      " [122.31633905 130.36870205]\n",
      " [ 25.89829939  41.31368117]\n",
      " [ 95.32688473 117.44668487]]\n"
     ]
    }
   ],
   "source": [
    "# Print predictions\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 56.  70.]\n",
      " [ 81. 101.]\n",
      " [119. 133.]\n",
      " [ 22.  37.]\n",
      " [103. 119.]\n",
      " [ 56.  70.]\n",
      " [ 81. 101.]\n",
      " [119. 133.]\n",
      " [ 22.  37.]\n",
      " [103. 119.]\n",
      " [ 56.  70.]\n",
      " [ 81. 101.]\n",
      " [119. 133.]\n",
      " [ 22.  37.]\n",
      " [103. 119.]]\n"
     ]
    }
   ],
   "source": [
    "# Print targets\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "2-linear-regression-pytorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
